{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Example 04: HNSW Graph Visualization\n",
    "# V√≠ d·ª• 4: Tr·ª±c quan h√≥a HNSW Graph-based Search\n",
    "\n",
    "Notebook n√†y minh h·ªça:\n",
    "- C√°ch HNSW (Hierarchical Navigable Small World) ho·∫°t ƒë·ªông\n",
    "- Visualization c·ªßa graph structure v√† hierarchical layers\n",
    "- Trade-off gi·ªØa M, efConstruction, efSearch\n",
    "- So s√°nh HNSW vs IVF\n",
    "- Performance analysis v√† tuning guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import networkx as nx\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from utils.data_generator import generate_random_vectors, generate_query_vectors\n",
    "from utils.benchmark import benchmark_index, progressive_recall_benchmark, compare_indexes\n",
    "from utils.visualization import plot_recall_vs_time\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Imports ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. HNSW Theory - L√Ω thuy·∫øt\n",
    "\n",
    "### C√°ch ho·∫°t ƒë·ªông c·ªßa HNSW:\n",
    "\n",
    "```\n",
    "Layer 2 (top):     A ‚Üê‚Üí E          (sparse, long-range connections)\n",
    "                   ‚Üì    ‚Üì\n",
    "Layer 1:       A ‚Üê‚Üí C ‚Üê‚Üí E ‚Üê‚Üí G    (medium density)\n",
    "               ‚Üì    ‚Üì    ‚Üì    ‚Üì\n",
    "Layer 0 (base): A-B-C-D-E-F-G-H   (dense, all vectors, short-range)\n",
    "```\n",
    "\n",
    "### Key Parameters:\n",
    "- **M**: S·ªë connections m·ªói node (16-64, th∆∞·ªùng d√πng 32)\n",
    "- **efConstruction**: Quality khi build (40-200)\n",
    "- **efSearch**: Quality khi search (16-512, tune runtime)\n",
    "\n",
    "### Search Process:\n",
    "1. Start t·ª´ entry point ·ªü layer cao nh·∫•t\n",
    "2. Greedy search xu·ªëng t·ª´ng layer\n",
    "3. Maintain dynamic list c·ªßa efSearch candidates\n",
    "4. Return k nearest neighbors t·ª´ layer 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup v√† Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "dimension = 128\n",
    "n_vectors = 50000\n",
    "n_queries = 200\n",
    "k = 10\n",
    "\n",
    "# HNSW parameters\n",
    "M = 32\n",
    "efConstruction = 40\n",
    "efSearch = 16\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Dimension: {dimension}\")\n",
    "print(f\"  Database: {n_vectors:,} vectors\")\n",
    "print(f\"  Queries: {n_queries}\")\n",
    "print(f\"  k: {k}\")\n",
    "print(f\"\\nHNSW Parameters:\")\n",
    "print(f\"  M: {M}\")\n",
    "print(f\"  efConstruction: {efConstruction}\")\n",
    "print(f\"  efSearch: {efSearch}\")\n",
    "\n",
    "# Generate data\n",
    "np.random.seed(42)\n",
    "database_vectors = generate_random_vectors(n_vectors, dimension)\n",
    "query_vectors = generate_query_vectors(n_queries, dimension)\n",
    "\n",
    "print(f\"\\n‚úì Data ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build Indexes (Flat + HNSW + IVF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Flat for ground truth\n",
    "print(\"[1/3] Building Flat index...\")\n",
    "index_flat = faiss.IndexFlatL2(dimension)\n",
    "index_flat.add(database_vectors)\n",
    "gt_distances, gt_indices = index_flat.search(query_vectors, k)\n",
    "print(f\"  ‚úì Ground truth ready\\n\")\n",
    "\n",
    "# 2. HNSW\n",
    "print(\"[2/3] Building HNSW index...\")\n",
    "start = time.time()\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, M)\n",
    "index_hnsw.hnsw.efConstruction = efConstruction\n",
    "index_hnsw.add(database_vectors)\n",
    "index_hnsw.hnsw.efSearch = efSearch\n",
    "hnsw_build_time = time.time() - start\n",
    "print(f\"  ‚úì Build time: {hnsw_build_time:.3f}s\")\n",
    "print(f\"  ‚úì Max level: {index_hnsw.hnsw.max_level}\")\n",
    "print(f\"  ‚úì Entry point: {index_hnsw.hnsw.entry_point}\\n\")\n",
    "\n",
    "# 3. IVF for comparison\n",
    "print(\"[3/3] Building IVF index...\")\n",
    "nlist = int(np.sqrt(n_vectors))\n",
    "quantizer = faiss.IndexFlatL2(dimension)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist)\n",
    "index_ivf.train(database_vectors)\n",
    "index_ivf.add(database_vectors)\n",
    "index_ivf.nprobe = 10\n",
    "print(f\"  ‚úì IVF ready (nlist={nlist}, nprobe=10)\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"All indexes built!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. HNSW Graph Structure Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze HNSW structure\n",
    "print(\"HNSW Graph Structure Analysis:\\n\")\n",
    "\n",
    "max_level = index_hnsw.hnsw.max_level\n",
    "entry_point = index_hnsw.hnsw.entry_point\n",
    "\n",
    "print(f\"Graph Information:\")\n",
    "print(f\"  Max level: {max_level}\")\n",
    "print(f\"  Entry point: {entry_point}\")\n",
    "print(f\"  M (connections): {M}\")\n",
    "print(f\"  Total vectors: {index_hnsw.ntotal}\")\n",
    "\n",
    "# Estimate connections\n",
    "# Layer 0: each node has ~2*M connections\n",
    "# Higher layers: progressively fewer nodes\n",
    "est_connections = n_vectors * M * 2\n",
    "graph_memory_mb = (est_connections * 4) / (1024**2)  # Assume 4 bytes per connection\n",
    "\n",
    "print(f\"\\nEstimated Graph Properties:\")\n",
    "print(f\"  Total connections: ~{est_connections:,}\")\n",
    "print(f\"  Graph memory overhead: ~{graph_memory_mb:.2f} MB\")\n",
    "print(f\"  Avg connections per node: {M * 2}\")\n",
    "\n",
    "# Visualize layer distribution (theoretical)\n",
    "layer_nodes = []\n",
    "for layer in range(max_level + 1):\n",
    "    # Probability of node being in layer i is (1/M)^i\n",
    "    prob = (1.0 / M) ** layer\n",
    "    expected_nodes = int(n_vectors * prob)\n",
    "    layer_nodes.append(max(1, expected_nodes))\n",
    "    print(f\"  Layer {layer}: ~{expected_nodes:,} nodes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualization - HNSW Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize layer structure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Layer distribution\n",
    "ax = axes[0]\n",
    "layers = list(range(max_level + 1))\n",
    "colors_grad = plt.cm.viridis(np.linspace(0, 1, len(layers)))\n",
    "\n",
    "bars = ax.barh(layers, layer_nodes, color=colors_grad, edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Number of Nodes (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Layer', fontsize=12)\n",
    "ax.set_title('HNSW Layer Distribution', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "for i, (bar, count) in enumerate(zip(bars, layer_nodes)):\n",
    "    ax.text(count * 1.2, i, f'{count:,}', va='center', fontweight='bold')\n",
    "\n",
    "# Add annotations\n",
    "ax.annotate('Base layer\\n(all vectors)', xy=(layer_nodes[0], 0),\n",
    "            xytext=(layer_nodes[0]/3, 0.5), fontsize=10,\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "ax.annotate('Top layer\\n(entry point)', xy=(layer_nodes[-1], max_level),\n",
    "            xytext=(layer_nodes[-1]*5, max_level-0.5), fontsize=10,\n",
    "            arrowprops=dict(arrowstyle='->', color='red', lw=2))\n",
    "\n",
    "# Plot 2: Hierarchical structure visualization\n",
    "ax = axes[1]\n",
    "\n",
    "# Draw pyramid-like structure\n",
    "y_positions = np.arange(max_level + 1)\n",
    "for i, (layer, nodes) in enumerate(zip(layers, layer_nodes)):\n",
    "    # Width proportional to log of node count\n",
    "    width = np.log10(nodes + 1)\n",
    "    ax.barh(layer, width, height=0.8, color=colors_grad[i], \n",
    "            edgecolor='black', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Add text\n",
    "    ax.text(width/2, layer, f'Layer {layer}\\n{nodes:,} nodes',\n",
    "            ha='center', va='center', fontsize=10, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Relative Density (log scale)', fontsize=12)\n",
    "ax.set_ylabel('Layer', fontsize=12)\n",
    "ax.set_title('HNSW Hierarchical Structure', fontsize=14, fontweight='bold')\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlim(0, None)\n",
    "\n",
    "# Add arrows showing search direction\n",
    "for i in range(max_level):\n",
    "    ax.annotate('', xy=(0.5, i), xytext=(0.5, i+1),\n",
    "                arrowprops=dict(arrowstyle='->', color='red', lw=2, alpha=0.5))\n",
    "ax.text(0.2, max_level/2, 'Search\\nDirection', fontsize=11, \n",
    "        color='red', fontweight='bold', rotation=90, va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_hnsw_layers.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 04_hnsw_layers.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trade-off: efSearch vs Recall/Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark different efSearch values\n",
    "print(\"Benchmarking efSearch values...\\n\")\n",
    "\n",
    "efSearch_values = [4, 8, 16, 32, 64, 128, 256, 512]\n",
    "results = progressive_recall_benchmark(\n",
    "    index_hnsw,\n",
    "    query_vectors,\n",
    "    gt_indices,\n",
    "    'efSearch',\n",
    "    efSearch_values,\n",
    "    k\n",
    ")\n",
    "\n",
    "# Visualize\n",
    "plot_recall_vs_time(\n",
    "    results,\n",
    "    title='HNSW: efSearch vs Recall/Speed Trade-off',\n",
    "    save_path='04_efSearch_tradeoff.png'\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì ƒê√£ l∆∞u: 04_efSearch_tradeoff.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Detailed efSearch Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Recall curve\n",
    "ax = axes[0, 0]\n",
    "ax.plot(efSearch_values, results['recalls'], 'o-', linewidth=2, markersize=8)\n",
    "ax.axhline(0.9, color='red', linestyle='--', alpha=0.5, label='90% threshold')\n",
    "ax.axhline(0.95, color='orange', linestyle='--', alpha=0.5, label='95% threshold')\n",
    "ax.set_xlabel('efSearch', fontsize=12)\n",
    "ax.set_ylabel('Recall@10', fontsize=12)\n",
    "ax.set_title('Recall vs efSearch', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "\n",
    "# Plot 2: QPS curve\n",
    "ax = axes[0, 1]\n",
    "ax.plot(efSearch_values, results['qps'], 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax.set_xlabel('efSearch', fontsize=12)\n",
    "ax.set_ylabel('QPS', fontsize=12)\n",
    "ax.set_title('QPS vs efSearch', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Recall vs QPS (Pareto)\n",
    "ax = axes[1, 0]\n",
    "scatter = ax.scatter(results['qps'], results['recalls'], \n",
    "                     c=efSearch_values, cmap='viridis', \n",
    "                     s=200, edgecolors='black', linewidth=2)\n",
    "for i, ef in enumerate(efSearch_values):\n",
    "    ax.annotate(f'ef={ef}', \n",
    "                (results['qps'][i], results['recalls'][i]),\n",
    "                xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "ax.set_xlabel('QPS', fontsize=12)\n",
    "ax.set_ylabel('Recall@10', fontsize=12)\n",
    "ax.set_title('Recall vs QPS Trade-off', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax, label='efSearch')\n",
    "\n",
    "# Plot 4: Efficiency (Recall per ms)\n",
    "ax = axes[1, 1]\n",
    "avg_latency = [t / len(query_vectors) * 1000 for t in results['search_times']]\n",
    "efficiency = [r / lat for r, lat in zip(results['recalls'], avg_latency)]\n",
    "ax.plot(efSearch_values, efficiency, 'o-', linewidth=2, markersize=8, color='purple')\n",
    "ax.set_xlabel('efSearch', fontsize=12)\n",
    "ax.set_ylabel('Recall per ms (efficiency)', fontsize=12)\n",
    "ax.set_title('Search Efficiency', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Mark optimal point\n",
    "optimal_idx = np.argmax(efficiency)\n",
    "ax.scatter([efSearch_values[optimal_idx]], [efficiency[optimal_idx]],\n",
    "           s=500, c='red', marker='*', edgecolors='black', linewidth=2,\n",
    "           label=f'Optimal: ef={efSearch_values[optimal_idx]}', zorder=5)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_efSearch_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úì ƒê√£ l∆∞u: 04_efSearch_analysis.png\")\n",
    "print(f\"\\nüí° Optimal efSearch: {efSearch_values[optimal_idx]} \")\n",
    "print(f\"   Recall: {results['recalls'][optimal_idx]:.3f}\")\n",
    "print(f\"   QPS: {results['qps'][optimal_idx]:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Compare Different M Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different M values\n",
    "print(\"Testing different M values...\\n\")\n",
    "\n",
    "M_values = [8, 16, 32, 64]\n",
    "M_results = {\n",
    "    'M': [],\n",
    "    'build_time': [],\n",
    "    'recall': [],\n",
    "    'qps': [],\n",
    "    'size_mb': []\n",
    "}\n",
    "\n",
    "# Use small subset for faster testing\n",
    "test_size = 10000\n",
    "test_vectors = database_vectors[:test_size]\n",
    "test_queries = query_vectors[:50]\n",
    "\n",
    "# Ground truth for test set\n",
    "test_flat = faiss.IndexFlatL2(dimension)\n",
    "test_flat.add(test_vectors)\n",
    "_, test_gt = test_flat.search(test_queries, k)\n",
    "\n",
    "for M_val in M_values:\n",
    "    print(f\"Testing M={M_val}...\")\n",
    "    \n",
    "    # Build\n",
    "    start = time.time()\n",
    "    idx = faiss.IndexHNSWFlat(dimension, M_val)\n",
    "    idx.hnsw.efConstruction = 40\n",
    "    idx.add(test_vectors)\n",
    "    idx.hnsw.efSearch = 64\n",
    "    build_time = time.time() - start\n",
    "    \n",
    "    # Benchmark\n",
    "    bench = benchmark_index(idx, test_queries, k, test_gt)\n",
    "    \n",
    "    # Memory\n",
    "    from utils.benchmark import get_index_size\n",
    "    size_info = get_index_size(idx)\n",
    "    \n",
    "    # Store\n",
    "    M_results['M'].append(M_val)\n",
    "    M_results['build_time'].append(build_time)\n",
    "    M_results['recall'].append(bench[f'recall@{k}'])\n",
    "    M_results['qps'].append(bench['qps'])\n",
    "    M_results['size_mb'].append(size_info['size_mb'])\n",
    "    \n",
    "    print(f\"  Build: {build_time:.3f}s, Recall: {bench[f'recall@{k}']:.3f}, \"\n",
    "          f\"QPS: {bench['qps']:.1f}, Size: {size_info['size_mb']:.2f}MB\")\n",
    "\n",
    "print(\"\\n‚úì M comparison complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize M comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Recall vs M\n",
    "ax = axes[0, 0]\n",
    "ax.plot(M_results['M'], M_results['recall'], 'o-', linewidth=2, markersize=10)\n",
    "ax.set_xlabel('M (connections)', fontsize=12)\n",
    "ax.set_ylabel('Recall@10', fontsize=12)\n",
    "ax.set_title('Recall vs M', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([0, 1.05])\n",
    "\n",
    "# Plot 2: Build time vs M\n",
    "ax = axes[0, 1]\n",
    "ax.plot(M_results['M'], M_results['build_time'], 'o-', \n",
    "        linewidth=2, markersize=10, color='orange')\n",
    "ax.set_xlabel('M (connections)', fontsize=12)\n",
    "ax.set_ylabel('Build Time (seconds)', fontsize=12)\n",
    "ax.set_title('Build Time vs M', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Memory vs M\n",
    "ax = axes[1, 0]\n",
    "ax.plot(M_results['M'], M_results['size_mb'], 'o-', \n",
    "        linewidth=2, markersize=10, color='green')\n",
    "ax.set_xlabel('M (connections)', fontsize=12)\n",
    "ax.set_ylabel('Memory Size (MB)', fontsize=12)\n",
    "ax.set_title('Memory vs M', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Multi-metric radar\n",
    "ax = axes[1, 1]\n",
    "# Normalize metrics for comparison\n",
    "norm_recall = np.array(M_results['recall'])\n",
    "norm_qps = np.array(M_results['qps']) / max(M_results['qps'])\n",
    "norm_build = 1 - (np.array(M_results['build_time']) / max(M_results['build_time']))\n",
    "norm_memory = 1 - (np.array(M_results['size_mb']) / max(M_results['size_mb']))\n",
    "\n",
    "x = np.arange(len(M_results['M']))\n",
    "width = 0.2\n",
    "ax.bar(x - 1.5*width, norm_recall, width, label='Recall', alpha=0.8)\n",
    "ax.bar(x - 0.5*width, norm_qps, width, label='Speed (norm)', alpha=0.8)\n",
    "ax.bar(x + 0.5*width, norm_build, width, label='Build Speed (norm)', alpha=0.8)\n",
    "ax.bar(x + 1.5*width, norm_memory, width, label='Memory Eff (norm)', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('M value', fontsize=12)\n",
    "ax.set_ylabel('Normalized Score', fontsize=12)\n",
    "ax.set_title('Multi-metric Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'M={m}' for m in M_results['M']])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_M_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 04_M_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. HNSW vs IVF Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare HNSW vs IVF\n",
    "print(\"Comparing HNSW vs IVF...\\n\")\n",
    "\n",
    "indexes = {\n",
    "    'Flat': index_flat,\n",
    "    'HNSW (ef=16)': index_hnsw,\n",
    "    'IVF (np=10)': index_ivf\n",
    "}\n",
    "\n",
    "# Reset efSearch to 16 for fair comparison\n",
    "index_hnsw.hnsw.efSearch = 16\n",
    "\n",
    "compare_indexes(indexes, query_vectors, gt_indices, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed visual comparison\n",
    "from utils.benchmark import get_index_size\n",
    "\n",
    "comparison = {}\n",
    "for name, idx in indexes.items():\n",
    "    bench = benchmark_index(idx, query_vectors, k, gt_indices)\n",
    "    size = get_index_size(idx)\n",
    "    comparison[name] = {\n",
    "        'recall': bench[f'recall@{k}'],\n",
    "        'qps': bench['qps'],\n",
    "        'size_mb': size['size_mb']\n",
    "    }\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "names = list(comparison.keys())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "# Plot 1: Recall\n",
    "ax = axes[0]\n",
    "recalls = [comparison[n]['recall'] for n in names]\n",
    "bars = ax.barh(names, recalls, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('Recall@10', fontsize=12)\n",
    "ax.set_title('Recall Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xlim([0, 1.05])\n",
    "for i, (bar, val) in enumerate(zip(bars, recalls)):\n",
    "    ax.text(val + 0.02, i, f'{val:.3f}', va='center', fontweight='bold')\n",
    "\n",
    "# Plot 2: QPS\n",
    "ax = axes[1]\n",
    "qps_vals = [comparison[n]['qps'] for n in names]\n",
    "bars = ax.barh(names, qps_vals, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('QPS', fontsize=12)\n",
    "ax.set_title('Speed Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_xscale('log')\n",
    "for i, (bar, val) in enumerate(zip(bars, qps_vals)):\n",
    "    ax.text(val * 1.5, i, f'{val:.0f}', va='center', fontweight='bold')\n",
    "\n",
    "# Plot 3: Memory\n",
    "ax = axes[2]\n",
    "sizes = [comparison[n]['size_mb'] for n in names]\n",
    "bars = ax.barh(names, sizes, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('Memory (MB)', fontsize=12)\n",
    "ax.set_title('Memory Usage', fontsize=14, fontweight='bold')\n",
    "for i, (bar, val) in enumerate(zip(bars, sizes)):\n",
    "    ax.text(val + max(sizes)*0.02, i, f'{val:.1f}', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('04_hnsw_vs_ivf.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 04_hnsw_vs_ivf.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary v√† Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"HNSW SUMMARY AND RECOMMENDATIONS\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä HNSW Index Performance:\")\n",
    "print(f\"  Build time: {hnsw_build_time:.3f}s for {n_vectors:,} vectors\")\n",
    "print(f\"  Max level: {max_level}\")\n",
    "print(f\"  Graph layers: {max_level + 1}\")\n",
    "print(f\"  Total connections: ~{est_connections:,}\")\n",
    "\n",
    "print(f\"\\nüéØ Parameter Guidelines:\")\n",
    "print(f\"\\n  M (connections per node):\")\n",
    "print(f\"    ‚Ä¢ Range: 16-64\")\n",
    "print(f\"    ‚Ä¢ Recommended: 32\")\n",
    "print(f\"    ‚Ä¢ Higher M ‚Üí Better accuracy, more memory\")\n",
    "print(f\"    ‚Ä¢ Lower M ‚Üí Faster build, less memory\")\n",
    "\n",
    "print(f\"\\n  efConstruction (build quality):\")\n",
    "print(f\"    ‚Ä¢ Range: 40-200\")\n",
    "print(f\"    ‚Ä¢ Recommended: 40 (fast) to 100 (quality)\")\n",
    "print(f\"    ‚Ä¢ Higher ‚Üí Better index quality, slower build\")\n",
    "print(f\"    ‚Ä¢ Set once during build\")\n",
    "\n",
    "print(f\"\\n  efSearch (search quality):\")\n",
    "print(f\"    ‚Ä¢ Range: 16-512\")\n",
    "print(f\"    ‚Ä¢ Recommended: 16 (fast) to 128 (accurate)\")\n",
    "print(f\"    ‚Ä¢ Higher ‚Üí Better recall, slower search\")\n",
    "print(f\"    ‚Ä¢ **Can tune at runtime!**\")\n",
    "\n",
    "# Find best efSearch from results\n",
    "target_recall_idx = next((i for i, r in enumerate(results['recalls']) if r >= 0.95), -1)\n",
    "if target_recall_idx >= 0:\n",
    "    print(f\"\\n  üí° For 95% recall:\")\n",
    "    print(f\"     efSearch = {efSearch_values[target_recall_idx]}\")\n",
    "    print(f\"     QPS = {results['qps'][target_recall_idx]:.1f}\")\n",
    "\n",
    "print(f\"\\n‚öñÔ∏è HNSW vs IVF:\")\n",
    "print(f\"\\n  Use HNSW when:\")\n",
    "print(f\"    ‚úì Dataset < 10M vectors\")\n",
    "print(f\"    ‚úì Need very high accuracy (>95%)\")\n",
    "print(f\"    ‚úì Memory is available\")\n",
    "print(f\"    ‚úì Low latency is critical\")\n",
    "print(f\"    ‚úì Don't want to retrain\")\n",
    "\n",
    "print(f\"\\n  Use IVF when:\")\n",
    "print(f\"    ‚úì Dataset > 10M vectors\")\n",
    "print(f\"    ‚úì Memory is constrained\")\n",
    "print(f\"    ‚úì Can accept 90-95% recall\")\n",
    "print(f\"    ‚úì Need to combine with PQ\")\n",
    "\n",
    "print(f\"\\nüöÄ Production Tips:\")\n",
    "print(f\"  1. Build offline with high efConstruction (100-200)\")\n",
    "print(f\"  2. Start with efSearch=16, increase if needed\")\n",
    "print(f\"  3. Monitor latency and tune efSearch dynamically\")\n",
    "print(f\"  4. Use M=32 as default, adjust based on benchmarks\")\n",
    "print(f\"  5. Consider sharding if dataset > 10M vectors\")\n",
    "\n",
    "print(f\"\\nüíæ Memory Considerations:\")\n",
    "print(f\"  ‚Ä¢ Base vectors: {database_vectors.nbytes / (1024**2):.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Graph overhead: ~{graph_memory_mb:.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Total: ~{(database_vectors.nbytes / (1024**2)) + graph_memory_mb:.2f} MB\")\n",
    "print(f\"  ‚Ä¢ Ratio: {1 + graph_memory_mb/(database_vectors.nbytes / (1024**2)):.2f}x\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"‚úÖ HNSW is excellent for high-accuracy, low-latency search!\")\n",
    "print(f\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
