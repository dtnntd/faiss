{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vietnamese Text Search v·ªõi FAISS\n",
    "# T√¨m ki·∫øm VƒÉn b·∫£n Ti·∫øng Vi·ªát v·ªõi Google Embeddings\n",
    "\n",
    "Notebook n√†y demo:\n",
    "- **Real Vietnamese text dataset** (1000+ chunks)\n",
    "- **Google Embedding API** ƒë·ªÉ t·∫°o embeddings\n",
    "- **So s√°nh c√°c ph∆∞∆°ng ph√°p FAISS**: Flat, IVF, HNSW\n",
    "- **Semantic search** v·ªõi queries ti·∫øng Vi·ªát\n",
    "- **Performance analysis** cho production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "### 1. Install dependencies\n",
    "```bash\n",
    "pip install google-generativeai python-dotenv faiss-cpu numpy pandas matplotlib seaborn\n",
    "```\n",
    "\n",
    "### 2. Setup Google API Key\n",
    "1. Get API key t·ª´: https://makersuite.google.com/app/apikey\n",
    "2. T·∫°o file `.env` trong root directory:\n",
    "```\n",
    "GOOGLE_API_KEY=your_api_key_here\n",
    "```\n",
    "\n",
    "### 3. Generate dataset v√† embeddings\n",
    "```bash\n",
    "# Generate Vietnamese text\n",
    "python data/vietnamese_dataset_generator.py\n",
    "\n",
    "# Create embeddings (requires API key)\n",
    "python data/embed_vietnamese_text.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Imports ho√†n t·∫•t!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "from typing import List, Tuple\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Add parent to path\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "\n",
    "from data.embed_vietnamese_text import embed_query\n",
    "from utils.benchmark import benchmark_index, print_index_info\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Imports ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset v√† Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings...\n",
      "Loading texts...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/vietnamese_embeddings_texts.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m embeddings = np.load(embeddings_file)\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading texts...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtexts_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     17\u001b[39m     texts = [line.strip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úì Loaded:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/csdl/gk/faiss/.venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../data/vietnamese_embeddings_texts.txt'"
     ]
    }
   ],
   "source": [
    "# Load embeddings\n",
    "data_dir = '../data'\n",
    "embeddings_file = os.path.join(data_dir, 'vn.npy')\n",
    "texts_file = os.path.join(data_dir, 'vietnamese_embeddings_texts.txt')\n",
    "\n",
    "if not os.path.exists(embeddings_file):\n",
    "    print(\"‚ùå Embeddings not found!\")\n",
    "    print(\"Please run: python data/embed_vietnamese_text.py\")\n",
    "    print(\"Make sure you have GOOGLE_API_KEY in .env file\")\n",
    "    raise FileNotFoundError(embeddings_file)\n",
    "\n",
    "print(\"Loading embeddings...\")\n",
    "embeddings = np.load(embeddings_file)\n",
    "\n",
    "print(\"Loading texts...\")\n",
    "with open(texts_file, 'r', encoding='utf-8') as f:\n",
    "    texts = [line.strip() for line in f]\n",
    "\n",
    "print(f\"\\n‚úì Loaded:\")\n",
    "print(f\"  Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"  Number of texts: {len(texts)}\")\n",
    "print(f\"  Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(f\"  Memory size: {embeddings.nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "# Show samples\n",
    "print(f\"\\nSample texts:\")\n",
    "for i in range(min(5, len(texts))):\n",
    "    print(f\"  [{i+1}] {texts[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build FAISS Indexes\n",
    "\n",
    "Ch√∫ng ta s·∫Ω build 3 lo·∫°i index ƒë·ªÉ so s√°nh:\n",
    "1. **Flat** - 100% accuracy, baseline\n",
    "2. **IVF** - Fast, good for production\n",
    "3. **HNSW** - Best quality, moderate speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "n_texts = len(embeddings)\n",
    "\n",
    "print(f\"Building FAISS indexes for {n_texts} texts...\\n\")\n",
    "\n",
    "indexes = {}\n",
    "build_times = {}\n",
    "\n",
    "# Normalize embeddings for cosine similarity\n",
    "print(\"Normalizing embeddings for cosine similarity...\")\n",
    "faiss.normalize_L2(embeddings)\n",
    "print(\"‚úì Normalized\\n\")\n",
    "\n",
    "# 1. Flat Index (Baseline)\n",
    "print(\"[1/3] Building Flat Index...\")\n",
    "start = time.time()\n",
    "index_flat = faiss.IndexFlatIP(dimension)  # Inner Product for cosine\n",
    "index_flat.add(embeddings)\n",
    "build_times['Flat'] = time.time() - start\n",
    "indexes['Flat'] = index_flat\n",
    "print(f\"  ‚úì Build time: {build_times['Flat']:.3f}s\\n\")\n",
    "\n",
    "# 2. IVF Index\n",
    "print(\"[2/3] Building IVF Index...\")\n",
    "nlist = int(np.sqrt(n_texts))  # Rule of thumb\n",
    "start = time.time()\n",
    "quantizer = faiss.IndexFlatIP(dimension)\n",
    "index_ivf = faiss.IndexIVFFlat(quantizer, dimension, nlist, faiss.METRIC_INNER_PRODUCT)\n",
    "index_ivf.train(embeddings)\n",
    "index_ivf.add(embeddings)\n",
    "index_ivf.nprobe = 10\n",
    "build_times['IVF'] = time.time() - start\n",
    "indexes['IVF'] = index_ivf\n",
    "print(f\"  ‚úì Build time: {build_times['IVF']:.3f}s\")\n",
    "print(f\"  ‚úì nlist={nlist}, nprobe=10\\n\")\n",
    "\n",
    "# 3. HNSW Index\n",
    "print(\"[3/3] Building HNSW Index...\")\n",
    "M = 32\n",
    "start = time.time()\n",
    "index_hnsw = faiss.IndexHNSWFlat(dimension, M, faiss.METRIC_INNER_PRODUCT)\n",
    "index_hnsw.hnsw.efConstruction = 40\n",
    "index_hnsw.add(embeddings)\n",
    "index_hnsw.hnsw.efSearch = 32\n",
    "build_times['HNSW'] = time.time() - start\n",
    "indexes['HNSW'] = index_hnsw\n",
    "print(f\"  ‚úì Build time: {build_times['HNSW']:.3f}s\")\n",
    "print(f\"  ‚úì M={M}, efSearch=32\\n\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"All indexes built successfully!\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Semantic Search Demo\n",
    "\n",
    "Test v·ªõi c√°c queries ti·∫øng Vi·ªát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_vietnamese(query: str, index_name: str = 'HNSW', k: int = 5) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    T√¨m ki·∫øm semantic v·ªõi query ti·∫øng Vi·ªát\n",
    "    \n",
    "    Args:\n",
    "        query: C√¢u query ti·∫øng Vi·ªát\n",
    "        index_name: T√™n index ('Flat', 'IVF', 'HNSW')\n",
    "        k: S·ªë k·∫øt qu·∫£ tr·∫£ v·ªÅ\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with results\n",
    "    \"\"\"\n",
    "    # Embed query\n",
    "    print(f\"Embedding query: '{query}'...\")\n",
    "    query_emb = embed_query(query)\n",
    "    faiss.normalize_L2(query_emb)  # Normalize for cosine similarity\n",
    "    \n",
    "    # Search\n",
    "    index = indexes[index_name]\n",
    "    start = time.time()\n",
    "    distances, indices = index.search(query_emb, k)\n",
    "    search_time = time.time() - start\n",
    "    \n",
    "    # Prepare results\n",
    "    results = []\n",
    "    for i, (idx, dist) in enumerate(zip(indices[0], distances[0])):\n",
    "        results.append({\n",
    "            'rank': i + 1,\n",
    "            'text': texts[idx],\n",
    "            'similarity': float(dist),  # Cosine similarity (1 = perfect match)\n",
    "            'index': int(idx)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    print(f\"‚úì Found {k} results in {search_time*1000:.2f}ms using {index_name}\\n\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Test queries\n",
    "test_queries = [\n",
    "    \"tr√≠ tu·ªá nh√¢n t·∫°o v√† machine learning\",\n",
    "    \"s·ª©c kh·ªèe v√† t·∫≠p th·ªÉ d·ª•c\",\n",
    "    \"kinh doanh v√† kh·ªüi nghi·ªáp\",\n",
    "    \"gi√°o d·ª•c tr·ª±c tuy·∫øn\",\n",
    "    \"b·∫£o v·ªá m√¥i tr∆∞·ªùng\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demo search with first query\n",
    "query = test_queries[0]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(f\"Query: '{query}'\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = search_vietnamese(query, index_name='HNSW', k=10)\n",
    "\n",
    "print(\"Top 10 Results:\")\n",
    "print(\"=\"*70)\n",
    "for _, row in results.iterrows():\n",
    "    print(f\"\\n[{row['rank']}] Similarity: {row['similarity']:.4f}\")\n",
    "    print(f\"    {row['text']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. So s√°nh c√°c Index Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all index methods with same query\n",
    "print(\"Comparing index methods...\\n\")\n",
    "\n",
    "comparison_results = {}\n",
    "\n",
    "for index_name in ['Flat', 'IVF', 'HNSW']:\n",
    "    print(f\"Testing {index_name}...\")\n",
    "    results = search_vietnamese(query, index_name=index_name, k=10)\n",
    "    comparison_results[index_name] = results\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARISON SUMMARY\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for ax, (index_name, results) in zip(axes, comparison_results.items()):\n",
    "    # Plot similarity scores\n",
    "    ranks = results['rank'].values\n",
    "    similarities = results['similarity'].values\n",
    "    \n",
    "    bars = ax.barh(ranks, similarities, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Color code by similarity\n",
    "    colors = plt.cm.RdYlGn(similarities)\n",
    "    for bar, color in zip(bars, colors):\n",
    "        bar.set_color(color)\n",
    "    \n",
    "    ax.set_xlabel('Similarity Score', fontsize=11)\n",
    "    ax.set_ylabel('Rank', fontsize=11)\n",
    "    ax.set_title(f'{index_name} Index', fontsize=13, fontweight='bold')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (rank, sim) in enumerate(zip(ranks, similarities)):\n",
    "        ax.text(sim + 0.02, rank, f'{sim:.3f}', \n",
    "                va='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle(f'Search Results Comparison\\nQuery: \"{query}\"', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('vietnamese_search_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: vietnamese_search_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark v·ªõi nhi·ªÅu queries\n",
    "print(\"Benchmarking v·ªõi multiple queries...\\n\")\n",
    "\n",
    "# Embed all test queries\n",
    "print(\"Embedding test queries...\")\n",
    "test_embeddings = []\n",
    "for q in test_queries:\n",
    "    emb = embed_query(q)\n",
    "    faiss.normalize_L2(emb)\n",
    "    test_embeddings.append(emb[0])\n",
    "test_embeddings = np.array(test_embeddings, dtype='float32')\n",
    "print(f\"‚úì Embedded {len(test_queries)} queries\\n\")\n",
    "\n",
    "# Benchmark each index\n",
    "benchmark_results = {}\n",
    "\n",
    "for name, index in indexes.items():\n",
    "    print(f\"Benchmarking {name}...\")\n",
    "    \n",
    "    # Warmup\n",
    "    index.search(test_embeddings[:2], 10)\n",
    "    \n",
    "    # Measure\n",
    "    times = []\n",
    "    for _ in range(10):  # 10 iterations\n",
    "        start = time.time()\n",
    "        index.search(test_embeddings, 10)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    p95_time = np.percentile(times, 95)\n",
    "    qps = len(test_queries) / avg_time\n",
    "    \n",
    "    benchmark_results[name] = {\n",
    "        'avg_latency_ms': avg_time / len(test_queries) * 1000,\n",
    "        'p95_latency_ms': p95_time / len(test_queries) * 1000,\n",
    "        'qps': qps,\n",
    "        'build_time_s': build_times[name]\n",
    "    }\n",
    "    \n",
    "    print(f\"  Avg latency: {benchmark_results[name]['avg_latency_ms']:.2f}ms\")\n",
    "    print(f\"  QPS: {qps:.1f}\\n\")\n",
    "\n",
    "# Create comparison table\n",
    "df_bench = pd.DataFrame(benchmark_results).T\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PERFORMANCE COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(df_bench.to_string())\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "index_names = list(benchmark_results.keys())\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "\n",
    "# Plot 1: Average Latency\n",
    "ax = axes[0, 0]\n",
    "latencies = [benchmark_results[name]['avg_latency_ms'] for name in index_names]\n",
    "bars = ax.barh(index_names, latencies, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('Avg Latency (ms)', fontsize=12)\n",
    "ax.set_title('Average Search Latency', fontsize=14, fontweight='bold')\n",
    "for i, (bar, val) in enumerate(zip(bars, latencies)):\n",
    "    ax.text(val + max(latencies)*0.02, i, f'{val:.2f}ms', \n",
    "            va='center', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 2: QPS\n",
    "ax = axes[0, 1]\n",
    "qps_vals = [benchmark_results[name]['qps'] for name in index_names]\n",
    "bars = ax.barh(index_names, qps_vals, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('Queries Per Second', fontsize=12)\n",
    "ax.set_title('Throughput (QPS)', fontsize=14, fontweight='bold')\n",
    "for i, (bar, val) in enumerate(zip(bars, qps_vals)):\n",
    "    ax.text(val + max(qps_vals)*0.02, i, f'{val:.1f}', \n",
    "            va='center', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 3: Build Time\n",
    "ax = axes[1, 0]\n",
    "build_times_vals = [benchmark_results[name]['build_time_s'] for name in index_names]\n",
    "bars = ax.barh(index_names, build_times_vals, color=colors, edgecolor='black', linewidth=2)\n",
    "ax.set_xlabel('Build Time (seconds)', fontsize=12)\n",
    "ax.set_title('Index Build Time', fontsize=14, fontweight='bold')\n",
    "for i, (bar, val) in enumerate(zip(bars, build_times_vals)):\n",
    "    ax.text(val + max(build_times_vals)*0.02, i, f'{val:.3f}s', \n",
    "            va='center', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Plot 4: Latency vs QPS scatter\n",
    "ax = axes[1, 1]\n",
    "for i, name in enumerate(index_names):\n",
    "    lat = benchmark_results[name]['avg_latency_ms']\n",
    "    qps = benchmark_results[name]['qps']\n",
    "    ax.scatter(lat, qps, s=500, c=[colors[i]], \n",
    "               edgecolors='black', linewidth=2, zorder=5)\n",
    "    ax.annotate(name, (lat, qps), xytext=(10, 10),\n",
    "                textcoords='offset points', fontsize=11, fontweight='bold')\n",
    "ax.set_xlabel('Latency (ms)', fontsize=12)\n",
    "ax.set_ylabel('QPS', fontsize=12)\n",
    "ax.set_title('Latency vs Throughput', fontsize=14, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Vietnamese Text Search Performance', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('vietnamese_performance_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: vietnamese_performance_comparison.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Interactive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function ƒë·ªÉ test v·ªõi custom query\n",
    "def interactive_search(query_text: str, k: int = 5):\n",
    "    \"\"\"\n",
    "    Search v·ªõi custom query v√† hi·ªÉn th·ªã k·∫øt qu·∫£ t·ª´ t·∫•t c·∫£ indexes\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Query: '{query_text}'\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for index_name in ['Flat', 'IVF', 'HNSW']:\n",
    "        print(f\"\\n{index_name} Results:\")\n",
    "        print(\"-\"*80)\n",
    "        \n",
    "        results = search_vietnamese(query_text, index_name=index_name, k=k)\n",
    "        \n",
    "        for _, row in results.head(3).iterrows():  # Show top 3\n",
    "            print(f\"[{row['rank']}] Similarity: {row['similarity']:.4f}\")\n",
    "            print(f\"    {row['text'][:150]}...\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# Test v·ªõi c√°c queries kh√°c nhau\n",
    "print(\"Testing v·ªõi c√°c queries kh√°c nhau:\\n\")\n",
    "\n",
    "for q in test_queries[1:3]:  # Test 2 queries\n",
    "    interactive_search(q, k=5)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary v√† Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"VIETNAMESE TEXT SEARCH - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"  Texts: {len(texts):,}\")\n",
    "print(f\"  Embedding model: Google text-embedding-004\")\n",
    "print(f\"  Dimension: {dimension}\")\n",
    "print(f\"  Memory: {embeddings.nbytes / (1024**2):.2f} MB\")\n",
    "\n",
    "print(f\"\\n‚ö° Performance Comparison:\")\n",
    "print(f\"\\n  {'Index':<10} {'Latency':<15} {'QPS':<15} {'Build Time':<15}\")\n",
    "print(f\"  {'-'*55}\")\n",
    "for name in index_names:\n",
    "    print(f\"  {name:<10} \"\n",
    "          f\"{benchmark_results[name]['avg_latency_ms']:<15.2f} \"\n",
    "          f\"{benchmark_results[name]['qps']:<15.1f} \"\n",
    "          f\"{benchmark_results[name]['build_time_s']:<15.3f}\")\n",
    "\n",
    "# Find best\n",
    "best_latency = min(benchmark_results.items(), key=lambda x: x[1]['avg_latency_ms'])\n",
    "best_qps = max(benchmark_results.items(), key=lambda x: x[1]['qps'])\n",
    "\n",
    "print(f\"\\nüèÜ Winners:\")\n",
    "print(f\"  Lowest latency: {best_latency[0]} ({best_latency[1]['avg_latency_ms']:.2f}ms)\")\n",
    "print(f\"  Highest QPS: {best_qps[0]} ({best_qps[1]['qps']:.1f} QPS)\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "print(f\"\\n  For Vietnamese text search ({len(texts)} texts):\")\n",
    "if len(texts) < 10000:\n",
    "    print(f\"    ‚úì Use HNSW for best quality (high recall)\")\n",
    "    print(f\"    ‚úì Use Flat if you need 100% accuracy\")\n",
    "    print(f\"    ‚úì IVF is good balance for production\")\n",
    "else:\n",
    "    print(f\"    ‚úì Use IVF or IVF+PQ for large scale\")\n",
    "    print(f\"    ‚úì Consider sharding if >1M texts\")\n",
    "\n",
    "print(f\"\\n  Production deployment:\")\n",
    "print(f\"    ‚Ä¢ Cache embeddings for frequently queried texts\")\n",
    "print(f\"    ‚Ä¢ Batch queries when possible\")\n",
    "print(f\"    ‚Ä¢ Monitor latency P95 < 100ms\")\n",
    "print(f\"    ‚Ä¢ Consider GPU if dataset > 1M\")\n",
    "\n",
    "print(f\"\\n  Accuracy tips:\")\n",
    "print(f\"    ‚Ä¢ Use same embedding model for queries and documents\")\n",
    "print(f\"    ‚Ä¢ Normalize embeddings for cosine similarity\")\n",
    "print(f\"    ‚Ä¢ Consider reranking top-K results\")\n",
    "print(f\"    ‚Ä¢ A/B test different index types\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ Analysis Complete!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Scale Up**: Th·ª≠ v·ªõi dataset l·ªõn h∆°n (10K-100K texts)\n",
    "2. **Fine-tune**: Optimize index parameters (nprobe, efSearch)\n",
    "3. **Hybrid Search**: K·∫øt h·ª£p v·ªõi keyword search\n",
    "4. **Filtering**: Th√™m metadata filtering (category, date, etc.)\n",
    "5. **Production**: Build API service v·ªõi caching layer\n",
    "\n",
    "**Happy searching! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faiss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
