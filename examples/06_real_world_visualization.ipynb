{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS Example 06: Real-World Applications\n",
    "# V√≠ d·ª• 6: ·ª®ng d·ª•ng Th·ª±c t·∫ø v·ªõi Visualization\n",
    "\n",
    "Notebook n√†y minh h·ªça:\n",
    "- **Product Recommendation System** (E-commerce)\n",
    "- **Document Semantic Search**\n",
    "- **User-based Recommendations**\n",
    "- Practical patterns v√† best practices\n",
    "- Performance optimization cho production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from typing import List, Dict, Tuple\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.dirname(os.path.abspath('')))\n",
    "from utils.data_generator import generate_text_like_embeddings, normalize_vectors\n",
    "from utils.benchmark import benchmark_index, print_index_info\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úì Imports ho√†n t·∫•t!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 1: Product Recommendation System\n",
    "\n",
    "### Scenario:\n",
    "E-commerce platform v·ªõi 50K s·∫£n ph·∫©m. User ƒëang xem m·ªôt s·∫£n ph·∫©m, c·∫ßn recommend c√°c s·∫£n ph·∫©m t∆∞∆°ng t·ª±.\n",
    "\n",
    "### Solution:\n",
    "- Embeddings t·ª´ product images/descriptions (CLIP, ResNet, BERT, etc.)\n",
    "- FAISS index ƒë·ªÉ t√¨m similar products\n",
    "- Real-time recommendations v·ªõi low latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate product database\n",
    "print(\"Creating Product Database...\\n\")\n",
    "\n",
    "n_products = 50000\n",
    "embedding_dim = 256  # Typical for CLIP, ResNet\n",
    "n_categories = 20    # Electronics, Clothing, Home, etc.\n",
    "\n",
    "# Categories\n",
    "category_names = [\n",
    "    \"Electronics\", \"Clothing\", \"Home & Kitchen\", \"Books\", \"Sports\",\n",
    "    \"Toys\", \"Beauty\", \"Automotive\", \"Food\", \"Pet Supplies\",\n",
    "    \"Health\", \"Garden\", \"Office\", \"Music\", \"Movies\",\n",
    "    \"Baby\", \"Jewelry\", \"Shoes\", \"Watches\", \"Arts & Crafts\"\n",
    "]\n",
    "\n",
    "# Generate product metadata\n",
    "np.random.seed(42)\n",
    "products_df = pd.DataFrame({\n",
    "    'product_id': range(n_products),\n",
    "    'category': np.random.choice(category_names, n_products),\n",
    "    'price': np.random.lognormal(4, 1.5, n_products),\n",
    "    'rating': np.random.beta(8, 2, n_products) * 5,  # Skewed toward high ratings\n",
    "    'popularity': np.random.zipf(1.5, n_products)    # Power law distribution\n",
    "})\n",
    "\n",
    "# Generate embeddings (simulating CLIP or similar model)\n",
    "print(\"Generating product embeddings...\")\n",
    "product_embeddings = generate_text_like_embeddings(\n",
    "    n_products, \n",
    "    dimension=embedding_dim,\n",
    "    n_topics=n_categories\n",
    ")\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "product_embeddings = normalize_vectors(product_embeddings)\n",
    "\n",
    "print(f\"\\n‚úì Created {n_products:,} products\")\n",
    "print(f\"‚úì Embedding dimension: {embedding_dim}\")\n",
    "print(f\"‚úì Categories: {n_categories}\")\n",
    "print(f\"\\nSample products:\")\n",
    "print(products_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Product Embeddings Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings in 2D\n",
    "print(\"Reducing dimensions for visualization...\")\n",
    "\n",
    "# Sample for visualization\n",
    "n_sample = 2000\n",
    "sample_idx = np.random.choice(n_products, n_sample, replace=False)\n",
    "sample_embeddings = product_embeddings[sample_idx]\n",
    "sample_categories = products_df.iloc[sample_idx]['category'].values\n",
    "\n",
    "# PCA for quick 2D\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(sample_embeddings)\n",
    "\n",
    "print(f\"‚úì PCA explained variance: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "# Color by category\n",
    "unique_cats = list(set(sample_categories))\n",
    "cat_colors = {cat: i for i, cat in enumerate(unique_cats)}\n",
    "colors = [cat_colors[cat] for cat in sample_categories]\n",
    "\n",
    "scatter = ax.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
    "                     c=colors, cmap='tab20', alpha=0.6, s=30, edgecolors='none')\n",
    "\n",
    "ax.set_xlabel('First Principal Component', fontsize=12)\n",
    "ax.set_ylabel('Second Principal Component', fontsize=12)\n",
    "ax.set_title('Product Embeddings Space (PCA)', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Legend with top 10 categories\n",
    "top_cats = products_df['category'].value_counts().head(10).index\n",
    "legend_elements = [plt.scatter([], [], c=[cat_colors[cat]/len(unique_cats)], \n",
    "                               s=100, label=cat, cmap='tab20')\n",
    "                   for cat in top_cats if cat in unique_cats]\n",
    "ax.legend(handles=legend_elements, loc='best', fontsize=9, title='Top Categories')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('06_product_embeddings.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 06_product_embeddings.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Product Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build FAISS index for products\n",
    "print(\"Building FAISS index for products...\\n\")\n",
    "\n",
    "# For cosine similarity, use IndexFlatIP (Inner Product)\n",
    "# Vectors are already normalized\n",
    "\n",
    "# Choose index based on size\n",
    "if n_products < 100000:\n",
    "    print(\"Using HNSW for high accuracy + speed\")\n",
    "    index = faiss.IndexHNSWFlat(embedding_dim, 32)\n",
    "    index.hnsw.efConstruction = 40\n",
    "    \n",
    "    start = time.time()\n",
    "    index.add(product_embeddings)\n",
    "    build_time = time.time() - start\n",
    "    \n",
    "    index.hnsw.efSearch = 32\n",
    "    index_type = \"HNSW\"\n",
    "else:\n",
    "    print(\"Using IVF+PQ for large scale\")\n",
    "    nlist = int(np.sqrt(n_products))\n",
    "    m = 32\n",
    "    quantizer = faiss.IndexFlatIP(embedding_dim)\n",
    "    index = faiss.IndexIVFPQ(quantizer, embedding_dim, nlist, m, 8)\n",
    "    \n",
    "    start = time.time()\n",
    "    index.train(product_embeddings)\n",
    "    index.add(product_embeddings)\n",
    "    build_time = time.time() - start\n",
    "    \n",
    "    index.nprobe = 10\n",
    "    index_type = \"IVF+PQ\"\n",
    "\n",
    "print(f\"\\n‚úì Built {index_type} index in {build_time:.3f}s\")\n",
    "print_index_info(index, f\"{index_type} Product Index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Recommendation Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_products(product_id: int, k: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"Recommend similar products\"\"\"\n",
    "    \n",
    "    # Get product embedding\n",
    "    query_embedding = product_embeddings[product_id:product_id+1]\n",
    "    \n",
    "    # Search (k+1 because first result is the product itself)\n",
    "    distances, indices = index.search(query_embedding, k + 1)\n",
    "    \n",
    "    # Remove the query product itself\n",
    "    indices = indices[0][1:]\n",
    "    distances = distances[0][1:]\n",
    "    \n",
    "    # Get product info\n",
    "    recommendations = products_df.iloc[indices].copy()\n",
    "    recommendations['similarity'] = distances  # Cosine similarity (1 = identical)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Demo: Recommend for a random product\n",
    "query_product_id = np.random.randint(0, n_products)\n",
    "query_product = products_df.iloc[query_product_id]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PRODUCT RECOMMENDATION DEMO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nUser is viewing:\")\n",
    "print(f\"  Product ID: {query_product['product_id']}\")\n",
    "print(f\"  Category: {query_product['category']}\")\n",
    "print(f\"  Price: ${query_product['price']:.2f}\")\n",
    "print(f\"  Rating: {query_product['rating']:.1f}/5.0\")\n",
    "\n",
    "# Get recommendations\n",
    "start = time.time()\n",
    "recommendations = recommend_products(query_product_id, k=10)\n",
    "search_time = time.time() - start\n",
    "\n",
    "print(f\"\\nüì¶ Top 10 Recommended Products (found in {search_time*1000:.2f}ms):\")\n",
    "print(\"=\"*70)\n",
    "print(recommendations[['product_id', 'category', 'price', 'rating', 'similarity']].to_string(index=False))\n",
    "\n",
    "# Analyze recommendations\n",
    "same_category = (recommendations['category'] == query_product['category']).sum()\n",
    "print(f\"\\nüìä Analysis:\")\n",
    "print(f\"  Same category: {same_category}/10\")\n",
    "print(f\"  Avg similarity: {recommendations['similarity'].mean():.3f}\")\n",
    "print(f\"  Search latency: {search_time*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize query product and recommendations in 2D\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 7))\n",
    "\n",
    "# Get embeddings for query and recommendations\n",
    "query_emb = product_embeddings[query_product_id]\n",
    "rec_ids = recommendations['product_id'].values\n",
    "rec_embs = product_embeddings[rec_ids]\n",
    "\n",
    "# Combine with sample for context\n",
    "all_embs = np.vstack([sample_embeddings, query_emb.reshape(1, -1), rec_embs])\n",
    "all_2d = pca.transform(all_embs)\n",
    "\n",
    "sample_2d = all_2d[:len(sample_embeddings)]\n",
    "query_2d = all_2d[len(sample_embeddings)]\n",
    "rec_2d = all_2d[len(sample_embeddings)+1:]\n",
    "\n",
    "# Plot 1: Overview\n",
    "ax = axes[0]\n",
    "ax.scatter(sample_2d[:, 0], sample_2d[:, 1], \n",
    "           c='lightgray', alpha=0.3, s=10, label='Other products')\n",
    "ax.scatter(rec_2d[:, 0], rec_2d[:, 1],\n",
    "           c='green', s=150, alpha=0.7, edgecolors='black',\n",
    "           linewidth=2, label='Recommendations', zorder=4)\n",
    "ax.scatter(query_2d[0], query_2d[1],\n",
    "           c='red', marker='*', s=500, edgecolors='black',\n",
    "           linewidth=2, label='Query Product', zorder=5)\n",
    "\n",
    "# Draw lines\n",
    "for rec in rec_2d:\n",
    "    ax.plot([query_2d[0], rec[0]], [query_2d[1], rec[1]],\n",
    "            'g--', alpha=0.3, linewidth=1)\n",
    "\n",
    "ax.set_xlabel('PC1', fontsize=12)\n",
    "ax.set_ylabel('PC2', fontsize=12)\n",
    "ax.set_title('Product Recommendations Visualization', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Similarity distribution\n",
    "ax = axes[1]\n",
    "similarities = recommendations['similarity'].values\n",
    "ranks = np.arange(1, len(similarities) + 1)\n",
    "\n",
    "bars = ax.bar(ranks, similarities, color='skyblue', edgecolor='black', linewidth=1.5)\n",
    "ax.set_xlabel('Recommendation Rank', fontsize=12)\n",
    "ax.set_ylabel('Cosine Similarity', fontsize=12)\n",
    "ax.set_title('Similarity Scores', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(ranks)\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Color code same category\n",
    "for i, bar in enumerate(bars):\n",
    "    if recommendations.iloc[i]['category'] == query_product['category']:\n",
    "        bar.set_color('lightgreen')\n",
    "        bar.set_edgecolor('green')\n",
    "        bar.set_linewidth(2)\n",
    "\n",
    "# Add legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [\n",
    "    Patch(facecolor='lightgreen', edgecolor='green', linewidth=2, label='Same category'),\n",
    "    Patch(facecolor='skyblue', edgecolor='black', linewidth=1.5, label='Different category')\n",
    "]\n",
    "ax.legend(handles=legend_elements, fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('06_recommendation_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 06_recommendation_visualization.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Case 2: Batch Recommendations (User Behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate user viewing history\n",
    "print(\"=\"*70)\n",
    "print(\"USE CASE 2: User-based Recommendations\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nScenario: User has viewed multiple products, recommend based on browsing history\")\n",
    "\n",
    "# Simulate user history\n",
    "n_viewed = 5\n",
    "viewed_products = np.random.choice(n_products, n_viewed, replace=False)\n",
    "\n",
    "print(f\"\\nUser's browsing history ({n_viewed} products):\")\n",
    "for idx in viewed_products:\n",
    "    p = products_df.iloc[idx]\n",
    "    print(f\"  #{idx}: {p['category']}, ${p['price']:.2f}, Rating: {p['rating']:.1f}\")\n",
    "\n",
    "# Aggregate strategy: Average embeddings\n",
    "viewed_embeddings = product_embeddings[viewed_products]\n",
    "user_profile_embedding = viewed_embeddings.mean(axis=0, keepdims=True)\n",
    "user_profile_embedding = normalize_vectors(user_profile_embedding)\n",
    "\n",
    "# Search\n",
    "distances, indices = index.search(user_profile_embedding, 20)\n",
    "\n",
    "# Filter out already viewed products\n",
    "indices = indices[0]\n",
    "distances = distances[0]\n",
    "mask = ~np.isin(indices, viewed_products)\n",
    "indices = indices[mask][:10]\n",
    "distances = distances[mask][:10]\n",
    "\n",
    "user_recommendations = products_df.iloc[indices].copy()\n",
    "user_recommendations['similarity'] = distances\n",
    "\n",
    "print(f\"\\nüì¶ Recommended Products based on User Profile:\")\n",
    "print(user_recommendations[['product_id', 'category', 'price', 'rating', 'similarity']].to_string(index=False))\n",
    "\n",
    "# Category analysis\n",
    "viewed_categories = products_df.iloc[viewed_products]['category'].value_counts()\n",
    "rec_categories = user_recommendations['category'].value_counts()\n",
    "\n",
    "print(f\"\\nüìä Category Distribution:\")\n",
    "print(f\"  Viewed: {dict(viewed_categories)}\")\n",
    "print(f\"  Recommended: {dict(rec_categories)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Analysis for Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark for production readiness\n",
    "print(\"=\"*70)\n",
    "print(\"PRODUCTION PERFORMANCE ANALYSIS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test with different batch sizes\n",
    "batch_sizes = [1, 10, 50, 100, 500]\n",
    "latencies = []\n",
    "throughputs = []\n",
    "\n",
    "print(f\"\\nBenchmarking with different batch sizes...\\n\")\n",
    "print(f\"{'Batch Size':<12} {'Avg Latency':<15} {'Throughput':<15} {'P95 Latency':<15}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # Generate random queries\n",
    "    test_queries = product_embeddings[np.random.choice(n_products, batch_size)]\n",
    "    \n",
    "    # Warmup\n",
    "    index.search(test_queries[:min(5, batch_size)], 10)\n",
    "    \n",
    "    # Benchmark\n",
    "    times = []\n",
    "    for _ in range(20):  # 20 iterations\n",
    "        start = time.time()\n",
    "        index.search(test_queries, 10)\n",
    "        times.append(time.time() - start)\n",
    "    \n",
    "    avg_time = np.mean(times)\n",
    "    p95_time = np.percentile(times, 95)\n",
    "    throughput = batch_size / avg_time\n",
    "    \n",
    "    latencies.append(avg_time / batch_size * 1000)  # ms per query\n",
    "    throughputs.append(throughput)\n",
    "    \n",
    "    print(f\"{batch_size:<12} {avg_time/batch_size*1000:<15.3f} {throughput:<15.1f} {p95_time/batch_size*1000:<15.3f}\")\n",
    "\n",
    "print(f\"\\n‚úì Benchmark complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Latency\n",
    "ax1.plot(batch_sizes, latencies, 'o-', linewidth=2, markersize=8, color='red')\n",
    "ax1.axhline(10, color='green', linestyle='--', alpha=0.5, label='10ms target')\n",
    "ax1.axhline(100, color='orange', linestyle='--', alpha=0.5, label='100ms acceptable')\n",
    "ax1.set_xlabel('Batch Size', fontsize=12)\n",
    "ax1.set_ylabel('Avg Latency per Query (ms)', fontsize=12)\n",
    "ax1.set_title('Search Latency', fontsize=14, fontweight='bold')\n",
    "ax1.set_xscale('log')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: Throughput\n",
    "ax2.plot(batch_sizes, throughputs, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax2.set_xlabel('Batch Size', fontsize=12)\n",
    "ax2.set_ylabel('Throughput (queries/sec)', fontsize=12)\n",
    "ax2.set_title('Search Throughput', fontsize=14, fontweight='bold')\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('06_production_performance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì ƒê√£ l∆∞u: 06_production_performance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Best Practices Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PRODUCTION BEST PRACTICES\".center(80))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "üèóÔ∏è ARCHITECTURE:\n",
    "\n",
    "1. Index Selection:\n",
    "   ‚Ä¢ < 100K vectors: HNSW for best quality\n",
    "   ‚Ä¢ 100K-1M: IVF or HNSW\n",
    "   ‚Ä¢ > 1M: IVF+PQ for scale\n",
    "   ‚Ä¢ > 10M: Distributed/sharded setup\n",
    "\n",
    "2. Embedding Strategy:\n",
    "   ‚Ä¢ Normalize for cosine similarity (IndexFlatIP)\n",
    "   ‚Ä¢ Cache embeddings for frequently accessed items\n",
    "   ‚Ä¢ Batch encode for efficiency\n",
    "\n",
    "3. Serving Pattern:\n",
    "   ‚Ä¢ Load index into memory at startup\n",
    "   ‚Ä¢ Use connection pooling\n",
    "   ‚Ä¢ Implement caching layer (Redis)\n",
    "   ‚Ä¢ Monitor latency and set SLO (e.g., P95 < 50ms)\n",
    "\n",
    "‚ö° OPTIMIZATION:\n",
    "\n",
    "1. Batching:\n",
    "   ‚Ä¢ Batch similar requests together\n",
    "   ‚Ä¢ Optimal batch size: 10-100 queries\n",
    "   ‚Ä¢ Trade-off: latency vs throughput\n",
    "\n",
    "2. Filtering:\n",
    "   ‚Ä¢ Pre-filter by metadata before FAISS search\n",
    "   ‚Ä¢ Post-filter results (price range, category, etc.)\n",
    "   ‚Ä¢ Use IndexIDMap for filtering\n",
    "\n",
    "3. Updates:\n",
    "   ‚Ä¢ Rebuild index periodically (daily/weekly)\n",
    "   ‚Ä¢ Use IndexIDMap2 for dynamic updates\n",
    "   ‚Ä¢ Hot-swap indices with zero downtime\n",
    "\n",
    "üîí RELIABILITY:\n",
    "\n",
    "1. Monitoring:\n",
    "   ‚Ä¢ Track latency (P50, P95, P99)\n",
    "   ‚Ä¢ Monitor recall quality\n",
    "   ‚Ä¢ Alert on degradation\n",
    "\n",
    "2. Fallback:\n",
    "   ‚Ä¢ Have backup index type\n",
    "   ‚Ä¢ Implement timeout and retry\n",
    "   ‚Ä¢ Graceful degradation\n",
    "\n",
    "3. A/B Testing:\n",
    "   ‚Ä¢ Test different index types\n",
    "   ‚Ä¢ Measure business metrics (CTR, conversions)\n",
    "   ‚Ä¢ Iterate on parameters\n",
    "\n",
    "üí° TIPS:\n",
    "\n",
    "‚Ä¢ Start simple (Flat/HNSW), optimize later\n",
    "‚Ä¢ Measure everything - don't guess\n",
    "‚Ä¢ User experience > raw metrics\n",
    "‚Ä¢ Consider cold start problem\n",
    "‚Ä¢ Plan for growth (10x headroom)\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"Current Setup Performance:\")\n",
    "print(f\"  Index type: {index_type}\")\n",
    "print(f\"  Products: {n_products:,}\")\n",
    "print(f\"  Avg latency: {latencies[0]:.2f}ms\")\n",
    "print(f\"  Throughput: {throughputs[-1]:.0f} queries/sec\")\n",
    "print(f\"  Build time: {build_time:.2f}s\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate estimated capacity\n",
    "target_latency_ms = 50\n",
    "estimated_qps = 1000 / latencies[0] if latencies[0] < target_latency_ms else 0\n",
    "daily_queries = estimated_qps * 86400\n",
    "\n",
    "print(f\"\\nüìä Estimated Capacity (P50 < {target_latency_ms}ms):\")\n",
    "print(f\"  QPS: ~{estimated_qps:.0f}\")\n",
    "print(f\"  Daily queries: ~{daily_queries:,.0f}\")\n",
    "print(f\"  Monthly queries: ~{daily_queries * 30:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ REAL-WORLD APPLICATION COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\"\"\n",
    "In this notebook, you learned:\n",
    "\n",
    "‚úì How to build a product recommendation system\n",
    "‚úì User-based recommendations from browsing history\n",
    "‚úì Production performance optimization\n",
    "‚úì Best practices for deploying FAISS\n",
    "‚úì Monitoring and reliability patterns\n",
    "\n",
    "Next steps:\n",
    "‚Ä¢ Try with your own embeddings (CLIP, BERT, etc.)\n",
    "‚Ä¢ Implement filtering and business rules\n",
    "‚Ä¢ Build API service around FAISS\n",
    "‚Ä¢ Monitor and optimize for your use case\n",
    "‚Ä¢ Scale to millions of items\n",
    "\n",
    "Happy building! üöÄ\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
